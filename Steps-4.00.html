
Results
4
<p><b>Model Performance</b></p><p><img src="https://app.colaberry.com/uploads/ProjectStepsImages/1596/12/1.jpg" style="width: 50%;"></p><p>1. <b>Accuracy: 91.7%</b></p><p>This means the model correctly predicted the outcome in 91.7% of the test cases. It shows the overall effectiveness of the model across both positive and negative classes.</p><p>2. <b>F1: 94.8%</b></p><p>The F1 score combines both precision and recall to give a balanced view of model performance. A score of 94.8% indicates that the model maintains a strong balance between correctly identifying positive cases and avoiding false positives.</p><p>3. <b>Precision: 90.2%</b></p><p>Precision measures how often the modelâ€™s positive predictions were actually correct. A precision of 90.2% means that 9 out of 10 times the model predicted a positive outcome, it was right.</p><p>4.<b> Recall: 100.0%</b></p><p>Recall evaluates the model's ability to identify all actual positive outcomes. A recall of 100% means the model successfully identified every true positive case in the dataset.</p>

<a href="https://www.youtube.com/watch?v=LbX4X71-TFI&amp;t=11s" target="_blank">How to evaluate ML models</a>


